{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9477b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import sklearn.preprocessing\n",
    "import sklearn.model_selection\n",
    "import sklearn.neighbors\n",
    "import duckdb\n",
    "import unittest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7ada06",
   "metadata": {},
   "source": [
    "# Software Component Five: s5.0_relation.py\n",
    "\n",
    "**Params:** \n",
    "\n",
    "**Inputs:** Pandas Dataframe containing Pfam return data. Includes quantitative features (ID, some metric of percent similarlity) and string of amino acid sequence.\n",
    "\n",
    "**Outputs:** Quantitative functional similarlity metric.\n",
    "\n",
    "**Metrics:**\n",
    "\n",
    "**Packages:** Pandas, numpy, scipy, seaborn, fuzzywuzzy\n",
    "\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a12e2a",
   "metadata": {},
   "source": [
    "**Subcomponent 1**: Test for pandas dataframe input\n",
    "\n",
    "**Use case**: User takes data from component 4 (where data is processed into pandas dataframe) and wants to pass it into relationship component."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77ff996",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "def check_input_type(sample_data):\n",
    "    tests that input data is a pandas dataframe with assert statement. \n",
    "    Output should pass unless assert statement fails.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea53fdb0",
   "metadata": {},
   "source": [
    "**Test**: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaebab2",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0208c336",
   "metadata": {},
   "source": [
    "**Subcomponent 2**: Checks that input data is cleaned property (does it have all of the features we need, and are the features we don't need removed).\n",
    "\n",
    "**Use case**: Input data does not include local E value, which we need as an input to our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6612c5",
   "metadata": {},
   "source": [
    "```\n",
    "def check_input_cleaning(sample_data):\n",
    "    if 'badstring' in df[]:\n",
    "        df = df.drop(df['string']\n",
    "    if 'goodstring' not in df[]:\n",
    "        raise ValueError\n",
    "    Clean out NAN's\n",
    "    Output: returns value count for columns we do need, and raises an error if we are missing data\n",
    "   \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42761cb",
   "metadata": {},
   "source": [
    "**Test**: assert str(type('nan object')) not in sample_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b62a38",
   "metadata": {},
   "source": [
    "```\n",
    "def check_strings(sample_data, sequence1 = sample_data['meso_seq], sequence2 = sample_data['thermo_seq']):\n",
    "    checks that input data has two protein sequences\n",
    "    raise error if number of sequences not = 2\n",
    "    raise error if len(sequence1) =/ len(sequence2)\n",
    "    Output: Nothing if test passes\n",
    "   \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebdb5e8",
   "metadata": {},
   "source": [
    "**Test**: Use unit test w/ self.assertTrue(False) method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a129b5",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea61071",
   "metadata": {},
   "source": [
    "**Subcomponent 3**: Train the model with sample data.\n",
    "\n",
    "**Use case**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580c697e",
   "metadata": {},
   "source": [
    "```\n",
    "def train_model(sample_data):\n",
    "    import scipy, numpy\n",
    "    Split data into dev and test (0.8/0.2 for now)\n",
    "    Train model (need to specify which kind of ML model we will use - I think linear regression)\n",
    "    Output: Print('Training successful!')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce3607d",
   "metadata": {},
   "source": [
    "**Test**: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16e1a90",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49907482",
   "metadata": {},
   "source": [
    "**Subcomponent 4**: Test the model with sample data.\n",
    "\n",
    "**Use case**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6636f45b",
   "metadata": {},
   "source": [
    "```\n",
    "def test_model(sample_data):\n",
    "    Runs data through model (linear regression (KNN?)\n",
    "    Output: Returns model_score, confusion matrix, MSE\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d65e2e8",
   "metadata": {},
   "source": [
    "**Test**: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d50b5f",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dec7a5",
   "metadata": {},
   "source": [
    "**Subcomponent 5**: Run confidence test on model output.\n",
    "\n",
    "**Use case:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3689d0",
   "metadata": {},
   "source": [
    "```\n",
    "def check_model_confidence(model_score, ci_data):\n",
    "    Runs a statistical test on model output and compares it to sample\n",
    "    Output: Returns a confidence score along with the model score\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1778f3e9",
   "metadata": {},
   "source": [
    "**Test**: Run confidence test on some data for which we know the confidence score\n",
    "      assert that the score is correct using numpy.isclose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f5fc59",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22901998",
   "metadata": {},
   "source": [
    "**Subcomponent 6**: Calculate a 'functionality' metric that is the ultimate output of component five. This will factor in information from multiple software, not just Pfam. This will be built during spring quarter.\n",
    "\n",
    "**Use case:** We need to test that our protein pairs have a near maximal functionality score! This can be used as a basis for eventual user input scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6171faf",
   "metadata": {},
   "source": [
    "```\n",
    "def calculate_functionality(model_score, sample_data):\n",
    "    runs user input data through some mathematical manipulation of their model score and input data\n",
    "    Output: returns a functionality score, print statement categorizing functionality score\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce85ad2",
   "metadata": {},
   "source": [
    "**Test**: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bf4a5d",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623750dd",
   "metadata": {},
   "source": [
    "# Plan Outline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36fc1a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
