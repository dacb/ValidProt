{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6202d016",
   "metadata": {},
   "source": [
    "- take input sequences and make blast database\n",
    "- create pairwise combos by index\n",
    "\n",
    "Alternatively:\n",
    "- take pairwise sequences\n",
    "- make blast database with unique seqs\n",
    "\n",
    "Now have blast database and pairwise sequences (need to assign indices)\n",
    "\n",
    "- Run Blast via iterator?\n",
    "- Generate feature set for model\n",
    "- Send to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "60fd48bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tempfile\n",
    "\n",
    "from typing import Collection\n",
    "\n",
    "from itertools import combinations\n",
    "import io\n",
    "\n",
    "from Bio.Blast.Applications import NcbimakeblastdbCommandline, NcbiblastpCommandline\n",
    "from Bio.Blast import NCBIXML\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio import SeqIO\n",
    "\n",
    "# https://biopython.org/docs/1.75/api/Bio.pairwise2.html\n",
    "from Bio import pairwise2\n",
    "from Bio.Align import substitution_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cb7ebe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "s50k = pd.read_csv('../learn2therm_sample_50k_exploration.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0a028427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "875"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s50k['thermo_index'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b35b359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>local_gap_compressed_percent_id</th>\n",
       "      <th>scaled_local_query_percent_id</th>\n",
       "      <th>scaled_local_symmetric_percent_id</th>\n",
       "      <th>query_align_len</th>\n",
       "      <th>query_align_cov</th>\n",
       "      <th>subject_align_len</th>\n",
       "      <th>subject_align_cov</th>\n",
       "      <th>bit_score</th>\n",
       "      <th>thermo_index</th>\n",
       "      <th>meso_index</th>\n",
       "      <th>prot_pair_index</th>\n",
       "      <th>meso_protein_int_index</th>\n",
       "      <th>thermo_protein_int_index</th>\n",
       "      <th>taxa_pair_index</th>\n",
       "      <th>local_gap_compressed_percent_id_16s</th>\n",
       "      <th>scaled_local_query_percent_id_16s</th>\n",
       "      <th>scaled_local_symmetric_percent_id_16s</th>\n",
       "      <th>query_align_cov_16s</th>\n",
       "      <th>subject_align_cov_16s</th>\n",
       "      <th>bit_score_16s</th>\n",
       "      <th>m_ogt</th>\n",
       "      <th>t_ogt</th>\n",
       "      <th>ogt_difference</th>\n",
       "      <th>m_protein_len</th>\n",
       "      <th>t_protein_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.00000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>5.000000e+04</td>\n",
       "      <td>5.000000e+04</td>\n",
       "      <td>5.000000e+04</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>24999.500000</td>\n",
       "      <td>0.349026</td>\n",
       "      <td>0.276478</td>\n",
       "      <td>0.270792</td>\n",
       "      <td>206.011660</td>\n",
       "      <td>0.791507</td>\n",
       "      <td>205.414920</td>\n",
       "      <td>0.770875</td>\n",
       "      <td>230.63206</td>\n",
       "      <td>8296.524160</td>\n",
       "      <td>8098.858120</td>\n",
       "      <td>9.105934e+07</td>\n",
       "      <td>3.213584e+07</td>\n",
       "      <td>2.600952e+07</td>\n",
       "      <td>362827.905140</td>\n",
       "      <td>0.906828</td>\n",
       "      <td>0.903266</td>\n",
       "      <td>0.904959</td>\n",
       "      <td>0.997153</td>\n",
       "      <td>0.997756</td>\n",
       "      <td>1061.404480</td>\n",
       "      <td>27.348365</td>\n",
       "      <td>51.505410</td>\n",
       "      <td>24.157045</td>\n",
       "      <td>269.985200</td>\n",
       "      <td>261.367700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14433.901067</td>\n",
       "      <td>0.096608</td>\n",
       "      <td>0.114404</td>\n",
       "      <td>0.116039</td>\n",
       "      <td>64.260901</td>\n",
       "      <td>0.144893</td>\n",
       "      <td>64.430548</td>\n",
       "      <td>0.179955</td>\n",
       "      <td>186.44859</td>\n",
       "      <td>5181.817228</td>\n",
       "      <td>4608.982941</td>\n",
       "      <td>5.233883e+07</td>\n",
       "      <td>1.868143e+07</td>\n",
       "      <td>1.662125e+07</td>\n",
       "      <td>229264.926253</td>\n",
       "      <td>0.015240</td>\n",
       "      <td>0.015626</td>\n",
       "      <td>0.015300</td>\n",
       "      <td>0.007108</td>\n",
       "      <td>0.003933</td>\n",
       "      <td>75.659661</td>\n",
       "      <td>3.737201</td>\n",
       "      <td>3.816972</td>\n",
       "      <td>3.586797</td>\n",
       "      <td>65.935753</td>\n",
       "      <td>69.675548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.164103</td>\n",
       "      <td>0.081301</td>\n",
       "      <td>0.045977</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.284553</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.082019</td>\n",
       "      <td>35.00000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.219000e+03</td>\n",
       "      <td>8.554400e+04</td>\n",
       "      <td>3.063480e+05</td>\n",
       "      <td>4885.000000</td>\n",
       "      <td>0.876590</td>\n",
       "      <td>0.836055</td>\n",
       "      <td>0.880026</td>\n",
       "      <td>0.871051</td>\n",
       "      <td>0.866066</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12499.750000</td>\n",
       "      <td>0.293750</td>\n",
       "      <td>0.204545</td>\n",
       "      <td>0.202020</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>0.673288</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>0.656854</td>\n",
       "      <td>118.00000</td>\n",
       "      <td>3841.000000</td>\n",
       "      <td>4121.000000</td>\n",
       "      <td>4.645832e+07</td>\n",
       "      <td>1.619813e+07</td>\n",
       "      <td>1.628730e+07</td>\n",
       "      <td>173976.750000</td>\n",
       "      <td>0.895995</td>\n",
       "      <td>0.893020</td>\n",
       "      <td>0.893531</td>\n",
       "      <td>0.996728</td>\n",
       "      <td>0.996719</td>\n",
       "      <td>1009.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>233.000000</td>\n",
       "      <td>226.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>24999.500000</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.244648</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>0.806584</td>\n",
       "      <td>186.00000</td>\n",
       "      <td>7134.000000</td>\n",
       "      <td>8046.000000</td>\n",
       "      <td>9.160212e+07</td>\n",
       "      <td>3.248324e+07</td>\n",
       "      <td>2.353333e+07</td>\n",
       "      <td>312362.000000</td>\n",
       "      <td>0.905983</td>\n",
       "      <td>0.902326</td>\n",
       "      <td>0.903543</td>\n",
       "      <td>0.997978</td>\n",
       "      <td>0.998009</td>\n",
       "      <td>1056.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>52.500000</td>\n",
       "      <td>24.500000</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>260.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>37499.250000</td>\n",
       "      <td>0.367257</td>\n",
       "      <td>0.308300</td>\n",
       "      <td>0.301639</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>267.00000</td>\n",
       "      <td>14062.000000</td>\n",
       "      <td>12103.000000</td>\n",
       "      <td>1.360713e+08</td>\n",
       "      <td>4.819069e+07</td>\n",
       "      <td>2.868282e+07</td>\n",
       "      <td>617814.000000</td>\n",
       "      <td>0.916172</td>\n",
       "      <td>0.912576</td>\n",
       "      <td>0.914698</td>\n",
       "      <td>0.999350</td>\n",
       "      <td>0.999350</td>\n",
       "      <td>1108.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>52.500000</td>\n",
       "      <td>24.500000</td>\n",
       "      <td>317.000000</td>\n",
       "      <td>311.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>49999.000000</td>\n",
       "      <td>0.985075</td>\n",
       "      <td>0.985075</td>\n",
       "      <td>0.985075</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1788.00000</td>\n",
       "      <td>16507.000000</td>\n",
       "      <td>16564.000000</td>\n",
       "      <td>1.814866e+08</td>\n",
       "      <td>6.542306e+07</td>\n",
       "      <td>6.476579e+07</td>\n",
       "      <td>744518.000000</td>\n",
       "      <td>0.999351</td>\n",
       "      <td>0.993544</td>\n",
       "      <td>0.996439</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1679.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0  local_gap_compressed_percent_id  \\\n",
       "count  50000.000000                     50000.000000   \n",
       "mean   24999.500000                         0.349026   \n",
       "std    14433.901067                         0.096608   \n",
       "min        0.000000                         0.164103   \n",
       "25%    12499.750000                         0.293750   \n",
       "50%    24999.500000                         0.325000   \n",
       "75%    37499.250000                         0.367257   \n",
       "max    49999.000000                         0.985075   \n",
       "\n",
       "       scaled_local_query_percent_id  scaled_local_symmetric_percent_id  \\\n",
       "count                   50000.000000                       50000.000000   \n",
       "mean                        0.276478                           0.270792   \n",
       "std                         0.114404                           0.116039   \n",
       "min                         0.081301                           0.045977   \n",
       "25%                         0.204545                           0.202020   \n",
       "50%                         0.250000                           0.244648   \n",
       "75%                         0.308300                           0.301639   \n",
       "max                         0.985075                           0.985075   \n",
       "\n",
       "       query_align_len  query_align_cov  subject_align_len  subject_align_cov  \\\n",
       "count     50000.000000     50000.000000       50000.000000       50000.000000   \n",
       "mean        206.011660         0.791507         205.414920           0.770875   \n",
       "std          64.260901         0.144893          64.430548           0.179955   \n",
       "min          19.000000         0.284553          19.000000           0.082019   \n",
       "25%         172.000000         0.673288         172.000000           0.656854   \n",
       "50%         210.000000         0.811321         209.000000           0.806584   \n",
       "75%         240.000000         0.923077         240.000000           0.923077   \n",
       "max         400.000000         1.000000         399.000000           1.000000   \n",
       "\n",
       "         bit_score  thermo_index    meso_index  prot_pair_index  \\\n",
       "count  50000.00000  50000.000000  50000.000000     5.000000e+04   \n",
       "mean     230.63206   8296.524160   8098.858120     9.105934e+07   \n",
       "std      186.44859   5181.817228   4608.982941     5.233883e+07   \n",
       "min       35.00000     37.000000      5.000000     1.219000e+03   \n",
       "25%      118.00000   3841.000000   4121.000000     4.645832e+07   \n",
       "50%      186.00000   7134.000000   8046.000000     9.160212e+07   \n",
       "75%      267.00000  14062.000000  12103.000000     1.360713e+08   \n",
       "max     1788.00000  16507.000000  16564.000000     1.814866e+08   \n",
       "\n",
       "       meso_protein_int_index  thermo_protein_int_index  taxa_pair_index  \\\n",
       "count            5.000000e+04              5.000000e+04     50000.000000   \n",
       "mean             3.213584e+07              2.600952e+07    362827.905140   \n",
       "std              1.868143e+07              1.662125e+07    229264.926253   \n",
       "min              8.554400e+04              3.063480e+05      4885.000000   \n",
       "25%              1.619813e+07              1.628730e+07    173976.750000   \n",
       "50%              3.248324e+07              2.353333e+07    312362.000000   \n",
       "75%              4.819069e+07              2.868282e+07    617814.000000   \n",
       "max              6.542306e+07              6.476579e+07    744518.000000   \n",
       "\n",
       "       local_gap_compressed_percent_id_16s  scaled_local_query_percent_id_16s  \\\n",
       "count                         50000.000000                       50000.000000   \n",
       "mean                              0.906828                           0.903266   \n",
       "std                               0.015240                           0.015626   \n",
       "min                               0.876590                           0.836055   \n",
       "25%                               0.895995                           0.893020   \n",
       "50%                               0.905983                           0.902326   \n",
       "75%                               0.916172                           0.912576   \n",
       "max                               0.999351                           0.993544   \n",
       "\n",
       "       scaled_local_symmetric_percent_id_16s  query_align_cov_16s  \\\n",
       "count                           50000.000000         50000.000000   \n",
       "mean                                0.904959             0.997153   \n",
       "std                                 0.015300             0.007108   \n",
       "min                                 0.880026             0.871051   \n",
       "25%                                 0.893531             0.996728   \n",
       "50%                                 0.903543             0.997978   \n",
       "75%                                 0.914698             0.999350   \n",
       "max                                 0.996439             1.000000   \n",
       "\n",
       "       subject_align_cov_16s  bit_score_16s         m_ogt         t_ogt  \\\n",
       "count           50000.000000   50000.000000  50000.000000  50000.000000   \n",
       "mean                0.997756    1061.404480     27.348365     51.505410   \n",
       "std                 0.003933      75.659661      3.737201      3.816972   \n",
       "min                 0.866066     891.000000      7.000000     41.000000   \n",
       "25%                 0.996719    1009.000000     27.000000     50.000000   \n",
       "50%                 0.998009    1056.000000     28.000000     52.500000   \n",
       "75%                 0.999350    1108.000000     29.000000     52.500000   \n",
       "max                 1.000000    1679.000000     40.000000     78.000000   \n",
       "\n",
       "       ogt_difference  m_protein_len  t_protein_len  \n",
       "count    50000.000000   50000.000000   50000.000000  \n",
       "mean        24.157045     269.985200     261.367700  \n",
       "std          3.586797      65.935753      69.675548  \n",
       "min         20.000000      30.000000      27.000000  \n",
       "25%         22.000000     233.000000     226.000000  \n",
       "50%         24.500000     267.000000     260.000000  \n",
       "75%         24.500000     317.000000     311.000000  \n",
       "max         56.000000     400.000000     400.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', 40)\n",
    "s50k.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d299fef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "s50k['m_protein_seq'][:10].to_csv('single_list_test.csv', index = False)\n",
    "s50k[['m_protein_seq', 't_protein_seq']][:10].to_csv('pair_list_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49257b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "slist = pd.read_csv('single_list_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "945087a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after function definition on line 7 (60237676.py, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[9], line 15\u001b[0;36m\u001b[0m\n\u001b[0;31m    class FafsaSingles(FafsaPairs):\u001b[0m\n\u001b[0m                                   ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 7\n"
     ]
    }
   ],
   "source": [
    "class FafsaPairs:\n",
    "    \n",
    "    def __init__(self, path):\n",
    "        \n",
    "        self.pairs = np.array(pd.read_csv(path))\n",
    "        \n",
    "    def align(self):\n",
    "        \n",
    "    \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "# Class for single sequence list input. Inherits from FAFSA_paired but is able to parse a single column input.\n",
    "class FafsaSingles(FafsaPairs):\n",
    "    \n",
    "    def __init__(self, path):\n",
    "        \n",
    "        self.pairs = list(combinations(pd.read_csv(path).values, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "584572c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FafsaPairs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test \u001b[38;5;241m=\u001b[39m \u001b[43mFafsaPairs\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpair_list_test.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'FafsaPairs' is not defined"
     ]
    }
   ],
   "source": [
    "test = FafsaPairs('pair_list_test.csv')\n",
    "test.pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8ce4257d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlastFiles:\n",
    "    \"\"\"Temporary files for use with BLAST CLI.\n",
    "    \n",
    "    Blast expects two input FASTA and produces an XML. The FASTA are redundant to CSV\n",
    "    we already have. These files are created for the context and removed after completion.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    query_iterator : iterator of (seq id, sequence)\n",
    "        sequences to be used as query\n",
    "    subject_iterator : iterator of (seq id, sequence)\n",
    "        sequences to be used as the \"database\"\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    query_filename : str, name of fasta file with query sequences\n",
    "    subject_filename : str, name of fasta file with subject sequences\n",
    "    output_filename : str, name of output file for blast to save reuslts, will be deleted out of context\n",
    "    \"\"\"\n",
    "    def __init__(self, query_iterator, subject_iterator, dbtype: str = 'nucl', dev_sample_num: int = None):\n",
    "        # we have to create the temporary fasta files\n",
    "        logger.debug(\"Creating temporary files to deposit blast inputs and outputs.\")\n",
    "        os.makedirs('./tmp/', exist_ok=True)\n",
    "        query_temp = tempfile.NamedTemporaryFile('w', delete=False, dir='./tmp/')\n",
    "        logger.debug(f\"query file: {query_temp.name}\")\n",
    "        if dev_sample_num is not None:\n",
    "            logger.debug(f\"Using only max {dev_sample_num} sequences from query and subject\")\n",
    "        self.qt = query_temp.name\n",
    "        n = 0\n",
    "        for id_, seq in query_iterator:\n",
    "            if seq == 'None' or seq is None:\n",
    "                continue\n",
    "            query_temp.write(f\">{id_}\\n{seq}\\n\")\n",
    "            n +=1\n",
    "            if dev_sample_num is not None:\n",
    "                if n >= dev_sample_num:\n",
    "                    break\n",
    "        query_temp.close()\n",
    "        logger.debug(f\"added {n} sequences to query file\")\n",
    "\n",
    "        # folder for subject DB after we make a fasta\n",
    "        subject_folder = tempfile.mkdtemp(dir='./tmp/')\n",
    "        self.st = subject_folder\n",
    "        subject_fasta_file = subject_folder+'/subs.fasta'\n",
    "        self.subject_fasta_file = subject_fasta_file\n",
    "        n = 0\n",
    "        file = open(subject_fasta_file, 'w')\n",
    "        for id_, seq in subject_iterator:\n",
    "            if seq == 'None' or seq is None:\n",
    "                continue\n",
    "            file.write(f\">{id_}\\n{seq}\\n\")\n",
    "            n +=1\n",
    "            if dev_sample_num is not None:\n",
    "                if n >= dev_sample_num:\n",
    "                    break\n",
    "        file.close()\n",
    "        logger.debug(f\"added {n} sequences to db file\")\n",
    "\n",
    "        # create db for it\n",
    "        NcbimakeblastdbCommandline(dbtype=dbtype, input_file=subject_fasta_file, parse_seqids=True)()\n",
    "        logger.debug(f\"created database\")\n",
    "        # create the output xml file\n",
    "        out_temp = tempfile.NamedTemporaryFile('w', delete=False, dir='./tmp')\n",
    "        self.ot = out_temp.name\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self.qt, self.subject_fasta_file, self.ot\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        logger.debug(\"Removing temporary files used by blast\")\n",
    "        os.remove(self.qt)\n",
    "        shutil.rmtree(self.st)\n",
    "        os.remove(self.ot)\n",
    "\n",
    "def csv_id_seq_iterator(csv_filepath: str, seq_col: str, index_col: str=None, id_filter: Collection = None, chunksize: int = 512, max_seq_length: int=None, **kwargs):\n",
    "    \"\"\"Returns a one by one iterator of seq ids and sequences to avoid OOM.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    csv_filepath : str\n",
    "        path to file containing data\n",
    "    seq_col : str\n",
    "        name of column containing sequences\n",
    "    index_col: str, default None\n",
    "        which column name is associated with the index, otherwise the 0th column will be used\n",
    "    id_filter : Collection, Optional\n",
    "        If given, only return sequences with the provided indexes\n",
    "    chunksize : int, default 512\n",
    "        Number of sequences that will be stored in memory at once.\n",
    "    max_seq_length : int, default None\n",
    "        Maximum length of sequence to return\n",
    "    **kwargs passed to pandas read csv \n",
    "    \"\"\"\n",
    "    # first get the row numbers to consider\n",
    "    if id_filter is not None:\n",
    "        if index_col is not None:\n",
    "            # get column positions to figure out which full col to load into memory\n",
    "            columns = pd.read_csv(csv_filepath, nrows=1, **kwargs).columns\n",
    "            index_col_position = np.argwhere(columns==index_col)[0][0]\n",
    "            # load only that column\n",
    "            row_indexes = pd.read_csv(csv_filepath, usecols=[index_col_position], **kwargs)\n",
    "            row_indexes = pd.Series(row_indexes.set_index(index_col, drop=True).index)\n",
    "        else:\n",
    "            row_indexes = pd.read_csv(csv_filepath, usecols=[0]).index # just take the first column becuase we only need the indexes\n",
    "            row_indexes = pd.Series(index=row_indexes, data=row_indexes)\n",
    "        row_indexes_to_keep_mask = row_indexes.isin(id_filter)\n",
    "        skiprows = lambda row_num: False if row_num==0 else not row_indexes_to_keep_mask.loc[row_num-1]\n",
    "        logger.debug(f\"{row_indexes_to_keep_mask.sum()} viable sequences in in file to iterate\")\n",
    "        seq_index_iterator = iter(list(row_indexes[row_indexes_to_keep_mask].values))\n",
    "    else:\n",
    "        skiprows=None\n",
    "\n",
    "    for i, df_chunk in enumerate(pd.read_csv(csv_filepath, chunksize=chunksize, skiprows=skiprows, dtype=str, **kwargs)):\n",
    "        if index_col is not None:\n",
    "            df_chunk = df_chunk.set_index(index_col, drop=True)\n",
    "        chunk = df_chunk[seq_col]\n",
    "        logger.debug(f'Iterating chunk {i} seq in {csv_filepath}')\n",
    "        for id_, seq in chunk.items():\n",
    "            # skip long sequences\n",
    "            if max_seq_length and len(seq) > max_seq_length:\n",
    "                continue\n",
    "            # in the case that there were no id filters, the id in the chunk corresponds to the correct sequence id\n",
    "            # but if there was a filter, many rows were skipped and the indexes got jumbled, so we have to recapitulate\n",
    "            # the correct seq index\n",
    "            if id_filter is not None:\n",
    "                yield next(seq_index_iterator), seq\n",
    "            else:\n",
    "                yield id_, seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8995459c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s50k.sample(2).to_csv('s5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "12c65124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>bit_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [query_id, subject_id, bit_score]\n",
       "Index: []"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.compute_metric('bit_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3ae865c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesos = pd.read_csv('s5.csv')[['m_protein_seq', 'meso_index']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a0da16",
   "metadata": {},
   "outputs": [],
   "source": [
    "NcbimakeblastdbCommandline(dbtype='prot', input_file=subject_fasta_file, parse_seqids=True)()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "96caaae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = open('test.fasta','w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b7d913ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in mesos.iterrows():\n",
    "    test.write(f\">{row[1]['meso_index']}\\n{row[1]['m_protein_seq']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "481307c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = NcbimakeblastdbCommandline(dbtype='prot', input_file='test.fasta', parse_seqids=True)()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4c0fe633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('', '')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NcbiblastpCommandline(query='test_q.fasta', db='test.fasta', outfmt=5, out='test_out', word_size=3, evalue=10000, max_target_seqs=100000)()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "ff95f37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlastMet:\n",
    "    \"\"\"Handles computation of metrics for each alignment in a blast record.\n",
    "\n",
    "    The HSP with the largest average sequence coverage is used for local metrics.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    blast_record : the record containing all hits for a query\n",
    "    \"\"\"\n",
    "    def __init__(self, blast_record):\n",
    "        recs = []\n",
    "        for rec in blast_records:\n",
    "            recs.append(rec)           # This is clunky\n",
    "        self.record = recs[0]\n",
    "        self.qid = self.record.query.split(' ')[0]\n",
    "\n",
    "    def id_hsp_best_cov(self, alignment):\n",
    "        \"\"\"Determine HSP with the most average coverage of both sequences.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Index of HSP with max average seq coverage\n",
    "        Max average coverage\n",
    "        \"\"\"\n",
    "        scores = []\n",
    "        #for alignment in self.record.alignments:\n",
    "        for hsp in alignment.hsps:\n",
    "            scores.append(\n",
    "                ((hsp.query_end +1 - hsp.query_start)/self.record.query_length + (hsp.sbjct_end +1 - hsp.sbjct_start)/\n",
    "                 alignment.length)/2)\n",
    "        return np.argmax(scores), max(scores)\n",
    "    \n",
    "    @staticmethod\n",
    "    def raw_gap_compressed_percent_id(n_matches, n_gaps, n_columns, n_compressed_gaps):\n",
    "        \"\"\"Percent matches in sequence, including but compressing gaps.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        n_matches : int, number of matches in match columns\n",
    "        n_gaps : number of gaps in match columns\n",
    "        n_columns : total number of alignment match columns\n",
    "        n_compressed_gaps : number of compressed gaps in match columns\n",
    "        \"\"\"\n",
    "        return n_matches / (n_columns - n_gaps + n_compressed_gaps)\n",
    "    \n",
    "    def compute_metric(self,metric_name: str):\n",
    "        \"\"\"Compute the metric with specified name for each alignment\"\"\"\n",
    "        if not hasattr(self, metric_name):\n",
    "            raise ValueError(f\"No metric found with name : {metric_name}\")\n",
    "        else:\n",
    "            metric = getattr(self, metric_name)\n",
    "\n",
    "        outputs = []\n",
    "        for alignment in self.record.alignments:\n",
    "            hsp_id, _ = self.id_hsp_best_cov(alignment)\n",
    "            hsp = alignment.hsps[hsp_id]\n",
    "            outputs.append((self.qid, alignment.hit_id.split('|')[-1], metric(alignment, hsp)))\n",
    "        return pd.DataFrame(data=outputs, columns=['query_id', 'subject_id', metric_name])\n",
    "\n",
    "    def subject_align_cov(self, alignment, hsp):\n",
    "        \"\"\"Fraction of AA on query string taken up by alignment\"\"\"\n",
    "        return (hsp.sbjct_end +1 - hsp.sbjct_start)/alignment.length\n",
    "    \n",
    "    def subject_align_len(self, alignment, hsp):\n",
    "        \"\"\"Length of AA on query string taken up by alignment\"\"\"\n",
    "        return int(hsp.sbjct_end +1 - hsp.sbjct_start)\n",
    "\n",
    "    def query_align_cov(self, alignment, hsp):\n",
    "        \"\"\"Fraction of AA on query string taken up by alignment\"\"\"\n",
    "        return (hsp.query_end +1 - hsp.query_start)/self.record.query_length\n",
    "\n",
    "    def query_align_len(self, alignment, hsp):\n",
    "        \"\"\"Length of AA on query string taken up by alignment\"\"\"\n",
    "        return int(hsp.query_end +1 - hsp.query_start)\n",
    "\n",
    "    def bit_score(self, alignment, hsp):\n",
    "        return hsp.score\n",
    "\n",
    "    def local_gap_compressed_percent_id(self, alignment, hsp):\n",
    "        \"\"\"Percent matches in match sequence, including but compressing gaps.\n",
    "        \n",
    "        The largest local HSP score is used\n",
    "        \"\"\"\n",
    "        n_matches = hsp.identities\n",
    "        n_gaps = hsp.gaps\n",
    "        n_columns = len(hsp.query)\n",
    "        n_compressed_gaps = len(re.findall('-+', hsp.query))+len(re.findall('-+', hsp.sbjct))\n",
    "        return self.raw_gap_compressed_percent_id(n_matches, n_gaps, n_columns, n_compressed_gaps)\n",
    "\n",
    "    def scaled_local_query_percent_id(self, alignment, hsp):\n",
    "        \"\"\"Percent matches in query sequence based on best HSP.\"\"\"\n",
    "        return hsp.identities/self.record.query_length\n",
    "\n",
    "    def scaled_local_symmetric_percent_id(self, alignment, hsp):\n",
    "        \"\"\"Percent matches compared to average seq length of query and subject based on best HSP\"\"\"\n",
    "        return 2*hsp.identities/(self.record.query_length + alignment.length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "33d65bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  query_id subject_id  local_gap_compressed_percent_id\n",
      "0      875       6565                         0.296296\n",
      "1      875       5029                         0.367347\n",
      "2      875       8505                         0.384615\n",
      "3      875       2327                         0.214286\n",
      "4      875      15825                         0.259259\n",
      "5      875       6801                         0.197368\n",
      "6      875       7923                         0.444444\n",
      "7      875       2373                         0.250000\n",
      "8      875      11651                         0.307692\n",
      "9      875       6824                         0.269231\n",
      "  query_id subject_id  scaled_local_query_percent_id\n",
      "0      875       6565                       0.079208\n",
      "1      875       5029                       0.089109\n",
      "2      875       8505                       0.049505\n",
      "3      875       2327                       0.029703\n",
      "4      875      15825                       0.034653\n",
      "5      875       6801                       0.074257\n",
      "6      875       7923                       0.039604\n",
      "7      875       2373                       0.039604\n",
      "8      875      11651                       0.019802\n",
      "9      875       6824                       0.034653\n",
      "  query_id subject_id  scaled_local_symmetric_percent_id\n",
      "0      875       6565                           0.076010\n",
      "1      875       5029                           0.076110\n",
      "2      875       8505                           0.045045\n",
      "3      875       2327                           0.026316\n",
      "4      875      15825                           0.032634\n",
      "5      875       6801                           0.055453\n",
      "6      875       7923                           0.033827\n",
      "7      875       2373                           0.027586\n",
      "8      875      11651                           0.016667\n",
      "9      875       6824                           0.024138\n",
      "  query_id subject_id  query_align_len\n",
      "0      875       6565               57\n",
      "1      875       5029               47\n",
      "2      875       8505               26\n",
      "3      875       2327               27\n",
      "4      875      15825               30\n",
      "5      875       6801               84\n",
      "6      875       7923               18\n",
      "7      875       2373               31\n",
      "8      875      11651               13\n",
      "9      875       6824               25\n",
      "  query_id subject_id  query_align_cov\n",
      "0      875       6565         0.282178\n",
      "1      875       5029         0.232673\n",
      "2      875       8505         0.128713\n",
      "3      875       2327         0.133663\n",
      "4      875      15825         0.148515\n",
      "5      875       6801         0.415842\n",
      "6      875       7923         0.089109\n",
      "7      875       2373         0.153465\n",
      "8      875      11651         0.064356\n",
      "9      875       6824         0.123762\n",
      "  query_id subject_id  subject_align_len\n",
      "0      875       6565                 54\n",
      "1      875       5029                 61\n",
      "2      875       8505                 26\n",
      "3      875       2327                 28\n",
      "4      875      15825                 26\n",
      "5      875       6801                 75\n",
      "6      875       7923                 18\n",
      "7      875       2373                 40\n",
      "8      875      11651                 13\n",
      "9      875       6824                 32\n",
      "  query_id subject_id  subject_align_cov\n",
      "0      875       6565           0.246575\n",
      "1      875       5029           0.225092\n",
      "2      875       8505           0.107438\n",
      "3      875       2327           0.110236\n",
      "4      875      15825           0.114537\n",
      "5      875       6801           0.221239\n",
      "6      875       7923           0.066421\n",
      "7      875       2373           0.105820\n",
      "8      875      11651           0.046763\n",
      "9      875       6824           0.084656\n",
      "  query_id subject_id  bit_score\n",
      "0      875       6565       33.0\n",
      "1      875       5029       42.0\n",
      "2      875       8505       35.0\n",
      "3      875       2327       17.0\n",
      "4      875      15825       29.0\n",
      "5      875       6801       16.0\n",
      "6      875       7923       27.0\n",
      "7      875       2373        5.0\n",
      "8      875      11651       24.0\n",
      "9      875       6824       18.0\n"
     ]
    }
   ],
   "source": [
    "result_handle = open('test_out')\n",
    "blast_records = NCBIXML.parse(result_handle)\n",
    "test = BlastMet(blast_records)\n",
    "\n",
    "for m in [\n",
    "    'local_gap_compressed_percent_id',\n",
    "    'scaled_local_query_percent_id',\n",
    "    'scaled_local_symmetric_percent_id',\n",
    "    'query_align_len',\n",
    "    'query_align_cov',\n",
    "    'subject_align_len',\n",
    "    'subject_align_cov',\n",
    "    'bit_score'\n",
    "]: \n",
    "    print(test.compute_metric(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2042794",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn2thermDB",
   "language": "python",
   "name": "learn2thermdb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
