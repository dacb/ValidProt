{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6202d016",
   "metadata": {},
   "source": [
    "- take input sequences and make blast database\n",
    "- create pairwise combos by index\n",
    "\n",
    "Alternatively:\n",
    "- take pairwise sequences\n",
    "- make blast database with unique seqs\n",
    "\n",
    "Now have blast database and pairwise sequences (need to assign indices)\n",
    "\n",
    "- Run Blast via iterator?\n",
    "- Generate feature set for model\n",
    "- Send to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60fd48bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryfran/miniconda3/envs/validprot/lib/python3.10/site-packages/Bio/pairwise2.py:278: BiopythonDeprecationWarning: Bio.pairwise2 has been deprecated, and we intend to remove it in a future release of Biopython. As an alternative, please consider using Bio.Align.PairwiseAligner as a replacement, and contact the Biopython developers if you still need the Bio.pairwise2 module.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tempfile\n",
    "\n",
    "from typing import Collection\n",
    "\n",
    "from itertools import combinations\n",
    "import io\n",
    "\n",
    "from Bio.Blast.Applications import NcbimakeblastdbCommandline, NcbiblastpCommandline\n",
    "from Bio.Blast import NCBIXML\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio import SeqIO\n",
    "\n",
    "# https://biopython.org/docs/1.75/api/Bio.pairwise2.html\n",
    "from Bio import pairwise2\n",
    "from Bio.Align import substitution_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cb7ebe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "s50k = pd.read_csv('../learn2therm_sample_50k_exploration.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a028427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>local_gap_compressed_percent_id</th>\n",
       "      <th>scaled_local_query_percent_id</th>\n",
       "      <th>scaled_local_symmetric_percent_id</th>\n",
       "      <th>query_align_len</th>\n",
       "      <th>query_align_cov</th>\n",
       "      <th>subject_align_len</th>\n",
       "      <th>subject_align_cov</th>\n",
       "      <th>bit_score</th>\n",
       "      <th>thermo_index</th>\n",
       "      <th>...</th>\n",
       "      <th>bit_score_16s</th>\n",
       "      <th>m_ogt</th>\n",
       "      <th>t_ogt</th>\n",
       "      <th>ogt_difference</th>\n",
       "      <th>m_protein_seq</th>\n",
       "      <th>t_protein_seq</th>\n",
       "      <th>m_protein_desc</th>\n",
       "      <th>t_protein_desc</th>\n",
       "      <th>m_protein_len</th>\n",
       "      <th>t_protein_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.287582</td>\n",
       "      <td>0.217822</td>\n",
       "      <td>0.215686</td>\n",
       "      <td>160</td>\n",
       "      <td>0.792079</td>\n",
       "      <td>152</td>\n",
       "      <td>0.737864</td>\n",
       "      <td>131</td>\n",
       "      <td>875</td>\n",
       "      <td>...</td>\n",
       "      <td>1153.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>50.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>MAESGTSRRADHLVPVPGPDAEPPAVADELLRAVGRGDEQAFGRLY...</td>\n",
       "      <td>MPSQITESERIELAERFERDALPLLDQLYSAALRMTRNPADAEDLV...</td>\n",
       "      <td>ECF RNA polymerase sigma factor SigK</td>\n",
       "      <td>sigma-70 family RNA polymerase sigma factor</td>\n",
       "      <td>206</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.319635</td>\n",
       "      <td>0.295359</td>\n",
       "      <td>0.297872</td>\n",
       "      <td>218</td>\n",
       "      <td>0.919831</td>\n",
       "      <td>226</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>282</td>\n",
       "      <td>11324</td>\n",
       "      <td>...</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>MARIALVDDDRNILTSVSMTLEAEGFEVETYNDGQSALDAFNKRMP...</td>\n",
       "      <td>MRVLLVEDDPNTSRSIEMMLTHANLNVYATDMGEEGIDLAKLYDYD...</td>\n",
       "      <td>response regulator transcription factor</td>\n",
       "      <td>response regulator transcription factor</td>\n",
       "      <td>233</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.279621</td>\n",
       "      <td>0.234127</td>\n",
       "      <td>0.218924</td>\n",
       "      <td>211</td>\n",
       "      <td>0.837302</td>\n",
       "      <td>210</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>96</td>\n",
       "      <td>875</td>\n",
       "      <td>...</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>MKDTVVFVTGAARGIGAHTARLAVARGARVALVGLEPHLLADLAAE...</td>\n",
       "      <td>MTPEQIFSGQTAIVTGGASGIGAATVEHIARRGGRVFSVDLSYDSP...</td>\n",
       "      <td>SDR family oxidoreductase</td>\n",
       "      <td>SDR family oxidoreductase</td>\n",
       "      <td>287</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.327273</td>\n",
       "      <td>0.200743</td>\n",
       "      <td>0.214712</td>\n",
       "      <td>166</td>\n",
       "      <td>0.617100</td>\n",
       "      <td>163</td>\n",
       "      <td>0.696581</td>\n",
       "      <td>175</td>\n",
       "      <td>875</td>\n",
       "      <td>...</td>\n",
       "      <td>1077.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>MTSGLWERVLDGVWVTIQLLVLSALLATAVSFVVGIARTHRLWIVR...</td>\n",
       "      <td>MAMSRRKRGQLARGIQYAILVIVVVVLALLADWGKIGKAFFDWEAA...</td>\n",
       "      <td>ectoine/hydroxyectoine ABC transporter permeas...</td>\n",
       "      <td>amino acid ABC transporter permease</td>\n",
       "      <td>234</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.338710</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.287671</td>\n",
       "      <td>60</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>71</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>61</td>\n",
       "      <td>9827</td>\n",
       "      <td>...</td>\n",
       "      <td>991.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>MIISLRRGLRFIRFIVFFAALVYLFYHVLDLFNGWISPVDQYQMPT...</td>\n",
       "      <td>MKRMVWRTLKVFIIFIACTLLFYFGLRFMHLEYEQFHRYEPPEGPA...</td>\n",
       "      <td>YqzK family protein</td>\n",
       "      <td>YqzK family protein</td>\n",
       "      <td>80</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  local_gap_compressed_percent_id  scaled_local_query_percent_id  \\\n",
       "0           0                         0.287582                       0.217822   \n",
       "1           1                         0.319635                       0.295359   \n",
       "2           2                         0.279621                       0.234127   \n",
       "3           3                         0.327273                       0.200743   \n",
       "4           4                         0.338710                       0.318182   \n",
       "\n",
       "   scaled_local_symmetric_percent_id  query_align_len  query_align_cov  \\\n",
       "0                           0.215686              160         0.792079   \n",
       "1                           0.297872              218         0.919831   \n",
       "2                           0.218924              211         0.837302   \n",
       "3                           0.214712              166         0.617100   \n",
       "4                           0.287671               60         0.909091   \n",
       "\n",
       "   subject_align_len  subject_align_cov  bit_score  thermo_index  ...  \\\n",
       "0                152           0.737864        131           875  ...   \n",
       "1                226           0.969957        282         11324  ...   \n",
       "2                210           0.731707         96           875  ...   \n",
       "3                163           0.696581        175           875  ...   \n",
       "4                 71           0.887500         61          9827  ...   \n",
       "\n",
       "   bit_score_16s  m_ogt  t_ogt  ogt_difference  \\\n",
       "0         1153.0   27.5   50.0            22.5   \n",
       "1         1014.0   25.0   54.0            29.0   \n",
       "2         1138.0   28.0   50.0            22.0   \n",
       "3         1077.0   28.0   50.0            22.0   \n",
       "4          991.0   30.0   50.0            20.0   \n",
       "\n",
       "                                       m_protein_seq  \\\n",
       "0  MAESGTSRRADHLVPVPGPDAEPPAVADELLRAVGRGDEQAFGRLY...   \n",
       "1  MARIALVDDDRNILTSVSMTLEAEGFEVETYNDGQSALDAFNKRMP...   \n",
       "2  MKDTVVFVTGAARGIGAHTARLAVARGARVALVGLEPHLLADLAAE...   \n",
       "3  MTSGLWERVLDGVWVTIQLLVLSALLATAVSFVVGIARTHRLWIVR...   \n",
       "4  MIISLRRGLRFIRFIVFFAALVYLFYHVLDLFNGWISPVDQYQMPT...   \n",
       "\n",
       "                                       t_protein_seq  \\\n",
       "0  MPSQITESERIELAERFERDALPLLDQLYSAALRMTRNPADAEDLV...   \n",
       "1  MRVLLVEDDPNTSRSIEMMLTHANLNVYATDMGEEGIDLAKLYDYD...   \n",
       "2  MTPEQIFSGQTAIVTGGASGIGAATVEHIARRGGRVFSVDLSYDSP...   \n",
       "3  MAMSRRKRGQLARGIQYAILVIVVVVLALLADWGKIGKAFFDWEAA...   \n",
       "4  MKRMVWRTLKVFIIFIACTLLFYFGLRFMHLEYEQFHRYEPPEGPA...   \n",
       "\n",
       "                                      m_protein_desc  \\\n",
       "0               ECF RNA polymerase sigma factor SigK   \n",
       "1            response regulator transcription factor   \n",
       "2                          SDR family oxidoreductase   \n",
       "3  ectoine/hydroxyectoine ABC transporter permeas...   \n",
       "4                                YqzK family protein   \n",
       "\n",
       "                                t_protein_desc  m_protein_len  t_protein_len  \n",
       "0  sigma-70 family RNA polymerase sigma factor            206            202  \n",
       "1      response regulator transcription factor            233            237  \n",
       "2                    SDR family oxidoreductase            287            252  \n",
       "3          amino acid ABC transporter permease            234            269  \n",
       "4                          YqzK family protein             80             66  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s50k.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2627aced",
   "metadata": {},
   "outputs": [],
   "source": [
    "s50k.sample(1).to_csv('s1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "945087a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FAFSA_paired:\n",
    "    \n",
    "    def __init__(self, seqs):\n",
    "        \n",
    "        self.seqs = seqs\n",
    "        \n",
    "    # Get it into fasta form\n",
    "        \n",
    "    def pair(self):\n",
    "        \n",
    "        return list(combinations(self.seqs, 2))\n",
    "        \n",
    "class FAFSA_single:\n",
    "    \n",
    "    def __init__(self, seqs):\n",
    "        \n",
    "        self.seqs = seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ce4257d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlastMetrics:\n",
    "    \"\"\"Handles computation of metrics for each alignment in a blast record.\n",
    "\n",
    "    The HSP with the largest average sequence coverage is used for local metrics.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    blast_record : the record containing all hits for a query\n",
    "    \"\"\"\n",
    "    def __init__(self, seqs):\n",
    "        self.seqs = seqs\n",
    "        \n",
    "        logger.debug(f\"Query {self.qid} with {len(self.record.alignments)} alignments.\")\n",
    "\n",
    "    def id_hsp_best_cov(self, alignment):\n",
    "        \"\"\"Determine HSP with the most average coverage of both sequences.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Index of HSP with max average seq coverage\n",
    "        Max average coverage\n",
    "        \"\"\"\n",
    "        scores = []\n",
    "        for hsp in alignment.hsps:\n",
    "            scores.append(\n",
    "                ((hsp.query_end +1 - hsp.query_start)/self.record.query_length + (hsp.sbjct_end +1 - hsp.sbjct_start)/alignment.length)/2)\n",
    "        return np.argmax(scores), max(scores)\n",
    "\n",
    "    def compute_metric(self, metric_name: str):\n",
    "        \"\"\"Compute the metric with specified name for each alignment\"\"\"\n",
    "        if not hasattr(self, metric_name):\n",
    "            raise ValueError(f\"No metric found with name : {metric_name}\")\n",
    "        else:\n",
    "            metric = getattr(self, metric_name)\n",
    "        \n",
    "        logger.debug(f\"Computing metric `{metric_name}` for all alignments in query {self.qid}\")\n",
    "\n",
    "        outputs = []\n",
    "        for alignment in self.record.alignments:\n",
    "            hsp_id, _ = self.id_hsp_best_cov(alignment)\n",
    "            hsp = alignment.hsps[hsp_id]\n",
    "            outputs.append((self.qid, alignment.hit_id.split('|')[-1], metric(alignment, hsp)))\n",
    "        return pd.DataFrame(data=outputs, columns=['query_id', 'subject_id', metric_name])\n",
    "\n",
    "    @staticmethod\n",
    "    def raw_gap_excluding_percent_id(n_matches, n_gaps, n_columns):\n",
    "        \"\"\"Percent matches in sequence, excluding gaps.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        n_matches : int, number of matches in match columns\n",
    "        n_gaps : number of gaps in match columns\n",
    "        n_columns : total number of alignment match columns\n",
    "        \"\"\"\n",
    "        return n_matches / (n_columns - n_gaps)\n",
    "\n",
    "    @staticmethod\n",
    "    def raw_gap_including_percent_id(n_matches, n_columns):\n",
    "        \"\"\"Percent matches in sequence, including gaps gaps.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        n_matches : int, number of matches in match columns\n",
    "        n_columns : total number of alignment match columns\n",
    "        \"\"\"\n",
    "        return n_matches / (n_columns)\n",
    "\n",
    "    @staticmethod\n",
    "    def raw_gap_compressed_percent_id(n_matches, n_gaps, n_columns, n_compressed_gaps):\n",
    "        \"\"\"Percent matches in sequence, including but compressing gaps.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        n_matches : int, number of matches in match columns\n",
    "        n_gaps : number of gaps in match columns\n",
    "        n_columns : total number of alignment match columns\n",
    "        n_compressed_gaps : number of compressed gaps in match columns\n",
    "        \"\"\"\n",
    "        return n_matches / (n_columns - n_gaps + n_compressed_gaps)\n",
    "\n",
    "    def local_gap_compressed_percent_id(self, alignment, hsp):\n",
    "        \"\"\"Percent matches in match sequence, including but compressing gaps.\n",
    "        \n",
    "        The largest local HSP score is used\n",
    "        \"\"\"\n",
    "        n_matches = hsp.identities\n",
    "        n_gaps = hsp.gaps\n",
    "        n_columns = len(hsp.query)\n",
    "        n_compressed_gaps = len(re.findall('-+', hsp.query))+len(re.findall('-+', hsp.sbjct))\n",
    "        return self.raw_gap_compressed_percent_id(n_matches, n_gaps, n_columns, n_compressed_gaps)\n",
    "\n",
    "    def scaled_local_query_percent_id(self, alignment, hsp):\n",
    "        \"\"\"Percent matches in query sequence based on best HSP.\"\"\"\n",
    "        return hsp.identities/self.record.query_length\n",
    "\n",
    "    def scaled_local_symmetric_percent_id(self, alignment, hsp):\n",
    "        \"\"\"Percent matches compared to average seq length of query and subject based on best HSP\"\"\"\n",
    "        return 2*hsp.identities/(self.record.query_length + alignment.length)\n",
    "\n",
    "    def local_E_value(self, alignment, hsp):\n",
    "        \"\"\"E value of HSP with most identities.\"\"\"\n",
    "        return hsp.expect\n",
    "\n",
    "    def query_align_start(self, alignment, hsp):\n",
    "        \"\"\"Start index of alignment in query.\"\"\"\n",
    "        return hsp.query_start\n",
    "\n",
    "    def query_align_end(self, alignment, hsp):\n",
    "        \"\"\"End index of alignment in query.\"\"\"\n",
    "        return hsp.query_end\n",
    "    \n",
    "    def subject_align_end(self, alignment, hsp):\n",
    "        \"\"\"End index of alignment in subject.\"\"\"\n",
    "        return hsp.sbjct_end\n",
    "\n",
    "    def subject_align_start(self, alignment, hsp):\n",
    "        \"\"\"Start index of alignment in subject.\"\"\"\n",
    "        return hsp.sbjct_start\n",
    "\n",
    "    def query_align_len(self, alignment, hsp):\n",
    "        \"\"\"Length of AA on query string taken up by alignment\"\"\"\n",
    "        return int(hsp.query_end +1 - hsp.query_start)\n",
    "\n",
    "    def query_align_cov(self, alignment, hsp):\n",
    "        \"\"\"Fraction of AA on query string taken up by alignment\"\"\"\n",
    "        return (hsp.query_end +1 - hsp.query_start)/self.record.query_length\n",
    "    \n",
    "    def subject_align_len(self, alignment, hsp):\n",
    "        \"\"\"Length of AA on query string taken up by alignment\"\"\"\n",
    "        return int(hsp.sbjct_end +1 - hsp.sbjct_start)\n",
    "\n",
    "    def subject_align_cov(self, alignment, hsp):\n",
    "        \"\"\"Fraction of AA on query string taken up by alignment\"\"\"\n",
    "        return (hsp.sbjct_end +1 - hsp.sbjct_start)/alignment.length\n",
    "    \n",
    "    def bit_score(self, alignment, hsp):\n",
    "        return hsp.score\n",
    "    \n",
    "class BlastFiles:\n",
    "    \"\"\"Temporary files for use with BLAST CLI.\n",
    "    \n",
    "    Blast expects two input FASTA and produces an XML. The FASTA are redundant to CSV\n",
    "    we already have. These files are created for the context and removed after completion.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    query_iterator : iterator of (seq id, sequence)\n",
    "        sequences to be used as query\n",
    "    subject_iterator : iterator of (seq id, sequence)\n",
    "        sequences to be used as the \"database\"\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    query_filename : str, name of fasta file with query sequences\n",
    "    subject_filename : str, name of fasta file with subject sequences\n",
    "    output_filename : str, name of output file for blast to save reuslts, will be deleted out of context\n",
    "    \"\"\"\n",
    "    def __init__(self, query_iterator, subject_iterator, dbtype: str = 'prot', dev_sample_num: int = None):\n",
    "        # we have to create the temporary fasta files\n",
    "        logger.debug(\"Creating temporary files to deposit blast inputs and outputs.\")\n",
    "        os.makedirs('./tmp/', exist_ok=True)\n",
    "        query_temp = tempfile.NamedTemporaryFile('w', delete=False, dir='./tmp/')\n",
    "        logger.debug(f\"query file: {query_temp.name}\")\n",
    "        if dev_sample_num is not None:\n",
    "            logger.debug(f\"Using only max {dev_sample_num} sequences from query and subject\")\n",
    "        self.qt = query_temp.name\n",
    "        n = 0\n",
    "        for id_, seq in query_iterator:\n",
    "            if seq == 'None' or seq is None:\n",
    "                continue\n",
    "            query_temp.write(f\">{id_}\\n{seq}\\n\")\n",
    "            n +=1\n",
    "            if dev_sample_num is not None:\n",
    "                if n >= dev_sample_num:\n",
    "                    break\n",
    "        query_temp.close()\n",
    "        logger.debug(f\"added {n} sequences to query file\")\n",
    "\n",
    "        # folder for subject DB after we make a fasta\n",
    "        subject_folder = tempfile.mkdtemp(dir='./tmp/')\n",
    "        self.st = subject_folder\n",
    "        subject_fasta_file = subject_folder+'/subs.fasta'\n",
    "        self.subject_fasta_file = subject_fasta_file\n",
    "        n = 0\n",
    "        file = open(subject_fasta_file, 'w')\n",
    "        for id_, seq in subject_iterator:\n",
    "            if seq == 'None' or seq is None:\n",
    "                continue\n",
    "            file.write(f\">{id_}\\n{seq}\\n\")\n",
    "            n +=1\n",
    "            if dev_sample_num is not None:\n",
    "                if n >= dev_sample_num:\n",
    "                    break\n",
    "        file.close()\n",
    "        logger.debug(f\"added {n} sequences to db file\")\n",
    "\n",
    "        # create db for it\n",
    "        NcbimakeblastdbCommandline(dbtype=dbtype, input_file=subject_fasta_file, parse_seqids=True)()\n",
    "        logger.debug(f\"created database\")\n",
    "        # create the output xml file\n",
    "        out_temp = tempfile.NamedTemporaryFile('w', delete=False, dir='./tmp')\n",
    "        self.ot = out_temp.name\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self.qt, self.subject_fasta_file, self.ot\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        logger.debug(\"Removing temporary files used by blast\")\n",
    "        os.remove(self.qt)\n",
    "        shutil.rmtree(self.st)\n",
    "        os.remove(self.ot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a1aa72e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FAFSA_input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[43mFAFSA_input\u001b[49m(test)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'FAFSA_input' is not defined"
     ]
    }
   ],
   "source": [
    "p = FAFSA_input(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4a1e92c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'p' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mp\u001b[49m\u001b[38;5;241m.\u001b[39mpair()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'p' is not defined"
     ]
    }
   ],
   "source": [
    "p.pair()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3511c881",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlastFiles:\n",
    "    \"\"\"Temporary files for use with BLAST CLI.\n",
    "    \n",
    "    Blast expects two input FASTA and produces an XML. The FASTA are redundant to CSV\n",
    "    we already have. These files are created for the context and removed after completion.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    query_iterator : iterator of (seq id, sequence)\n",
    "        sequences to be used as query\n",
    "    subject_iterator : iterator of (seq id, sequence)\n",
    "        sequences to be used as the \"database\"\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    query_filename : str, name of fasta file with query sequences\n",
    "    subject_filename : str, name of fasta file with subject sequences\n",
    "    output_filename : str, name of output file for blast to save reuslts, will be deleted out of context\n",
    "    \"\"\"\n",
    "    def __init__(self, query_iterator, subject_iterator, dbtype: str = 'prot', dev_sample_num: int = None):\n",
    "        # we have to create the temporary fasta files\n",
    "        logger.debug(\"Creating temporary files to deposit blast inputs and outputs.\")\n",
    "        os.makedirs('./tmp/', exist_ok=True)\n",
    "        query_temp = tempfile.NamedTemporaryFile('w', delete=False, dir='./tmp/')\n",
    "        logger.debug(f\"query file: {query_temp.name}\")\n",
    "        if dev_sample_num is not None:\n",
    "            logger.debug(f\"Using only max {dev_sample_num} sequences from query and subject\")\n",
    "        self.qt = query_temp.name\n",
    "        n = 0\n",
    "        for id_, seq in query_iterator:\n",
    "            if seq == 'None' or seq is None:\n",
    "                continue\n",
    "            query_temp.write(f\">{id_}\\n{seq}\\n\")\n",
    "            n +=1\n",
    "            if dev_sample_num is not None:\n",
    "                if n >= dev_sample_num:\n",
    "                    break\n",
    "        query_temp.close()\n",
    "        logger.debug(f\"added {n} sequences to query file\")\n",
    "\n",
    "        # folder for subject DB after we make a fasta\n",
    "        subject_folder = tempfile.mkdtemp(dir='./tmp/')\n",
    "        self.st = subject_folder\n",
    "        subject_fasta_file = subject_folder+'/subs.fasta'\n",
    "        self.subject_fasta_file = subject_fasta_file\n",
    "        n = 0\n",
    "        file = open(subject_fasta_file, 'w')\n",
    "        for id_, seq in subject_iterator:\n",
    "            if seq == 'None' or seq is None:\n",
    "                continue\n",
    "            file.write(f\">{id_}\\n{seq}\\n\")\n",
    "            n +=1\n",
    "            if dev_sample_num is not None:\n",
    "                if n >= dev_sample_num:\n",
    "                    break\n",
    "        file.close()\n",
    "        logger.debug(f\"added {n} sequences to db file\")\n",
    "\n",
    "        # create db for it\n",
    "        NcbimakeblastdbCommandline(dbtype=dbtype, input_file=subject_fasta_file, parse_seqids=True)()\n",
    "        logger.debug(f\"created database\")\n",
    "        # create the output xml file\n",
    "        out_temp = tempfile.NamedTemporaryFile('w', delete=False, dir='./tmp')\n",
    "        self.ot = out_temp.name\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self.qt, self.subject_fasta_file, self.ot\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        logger.debug(\"Removing temporary files used by blast\")\n",
    "        os.remove(self.qt)\n",
    "        shutil.rmtree(self.st)\n",
    "        os.remove(self.ot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1642c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_id_seq_iterator(csv_filepath: str, seq_col: str, index_col: str=None, id_filter: Collection = None, chunksize: int = 512, max_seq_length: int=None, **kwargs):\n",
    "    \"\"\"Returns a one by one iterator of seq ids and sequences to avoid OOM.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    csv_filepath : str\n",
    "        path to file containing data\n",
    "    seq_col : str\n",
    "        name of column containing sequences\n",
    "    index_col: str, default None\n",
    "        which column name is associated with the index, otherwise the 0th column will be used\n",
    "    id_filter : Collection, Optional\n",
    "        If given, only return sequences with the provided indexes\n",
    "    chunksize : int, default 512\n",
    "        Number of sequences that will be stored in memory at once.\n",
    "    max_seq_length : int, default None\n",
    "        Maximum length of sequence to return\n",
    "    **kwargs passed to pandas read csv \n",
    "    \"\"\"\n",
    "    # first get the row numbers to consider\n",
    "    if id_filter is not None:\n",
    "        if index_col is not None:\n",
    "            # get column positions to figure out which full col to load into memory\n",
    "            columns = pd.read_csv(csv_filepath, nrows=1, **kwargs).columns\n",
    "            index_col_position = np.argwhere(columns==index_col)[0][0]\n",
    "            # load only that column\n",
    "            row_indexes = pd.read_csv(csv_filepath, usecols=[index_col_position], **kwargs)\n",
    "            row_indexes = pd.Series(row_indexes.set_index(index_col, drop=True).index)\n",
    "        else:\n",
    "            row_indexes = pd.read_csv(csv_filepath, usecols=[0]).index # just take the first column becuase we only need the indexes\n",
    "            row_indexes = pd.Series(index=row_indexes, data=row_indexes)\n",
    "        row_indexes_to_keep_mask = row_indexes.isin(id_filter)\n",
    "        skiprows = lambda row_num: False if row_num==0 else not row_indexes_to_keep_mask.loc[row_num-1]\n",
    "        logger.debug(f\"{row_indexes_to_keep_mask.sum()} viable sequences in in file to iterate\")\n",
    "        seq_index_iterator = iter(list(row_indexes[row_indexes_to_keep_mask].values))\n",
    "    else:\n",
    "        skiprows=None\n",
    "\n",
    "    for i, df_chunk in enumerate(pd.read_csv(csv_filepath, chunksize=chunksize, skiprows=skiprows, dtype=str, **kwargs)):\n",
    "        if index_col is not None:\n",
    "            df_chunk = df_chunk.set_index(index_col, drop=True)\n",
    "        chunk = df_chunk[seq_col]\n",
    "        logger.debug(f'Iterating chunk {i} seq in {csv_filepath}')\n",
    "        for id_, seq in chunk.items():\n",
    "            # skip long sequences\n",
    "            if max_seq_length and len(seq) > max_seq_length:\n",
    "                continue\n",
    "            # in the case that there were no id filters, the id in the chunk corresponds to the correct sequence id\n",
    "            # but if there was a filter, many rows were skipped and the indexes got jumbled, so we have to recapitulate\n",
    "            # the correct seq index\n",
    "            if id_filter is not None:\n",
    "                yield next(seq_index_iterator), seq\n",
    "            else:\n",
    "                yield id_, seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8995459c",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter1 = csv_id_seq_iterator('s1.csv', seq_col='m_protein_seq', index_col='meso_index')\n",
    "iter2 = csv_id_seq_iterator('s1.csv', seq_col='t_protein_seq', index_col='thermo_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e9eb6f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c643aa2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ApplicationError",
     "evalue": "Non-zero return code 1 from 'blastp -out /home/ryfran/ValidProt/notebooks/c0-c2_exploration_plotting_sampling/tmp/tmptfofx1ll -outfmt 5 -query /home/ryfran/ValidProt/notebooks/c0-c2_exploration_plotting_sampling/tmp/tmpa6vofs8b -db ./tmp/tmp54nrgctw/subs.fasta -evalue 10000 -word_size 9 -max_target_seqs 100000', message 'BLAST query/options error: Word-size must be less than 8 for a tblastn, blastp or blastx search'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mApplicationError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m BlastFiles(iter1, iter2) \u001b[38;5;28;01mas\u001b[39;00m (qname, sname, oname):\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mNcbiblastpCommandline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutfmt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_target_seqs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(oname, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m     blast_result_records \u001b[38;5;241m=\u001b[39m NCBIXML\u001b[38;5;241m.\u001b[39mparse(f)\n",
      "File \u001b[0;32m~/miniconda3/envs/validprot/lib/python3.10/site-packages/Bio/Application/__init__.py:574\u001b[0m, in \u001b[0;36mAbstractCommandline.__call__\u001b[0;34m(self, stdin, stdout, stderr, cwd, env)\u001b[0m\n\u001b[1;32m    571\u001b[0m     stderr_arg\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_code:\n\u001b[0;32m--> 574\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ApplicationError(return_code, \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m), stdout_str, stderr_str)\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stdout_str, stderr_str\n",
      "\u001b[0;31mApplicationError\u001b[0m: Non-zero return code 1 from 'blastp -out /home/ryfran/ValidProt/notebooks/c0-c2_exploration_plotting_sampling/tmp/tmptfofx1ll -outfmt 5 -query /home/ryfran/ValidProt/notebooks/c0-c2_exploration_plotting_sampling/tmp/tmpa6vofs8b -db ./tmp/tmp54nrgctw/subs.fasta -evalue 10000 -word_size 9 -max_target_seqs 100000', message 'BLAST query/options error: Word-size must be less than 8 for a tblastn, blastp or blastx search'"
     ]
    }
   ],
   "source": [
    "with BlastFiles(iter1, iter2) as (qname, sname, oname):\n",
    "    NcbiblastpCommandline(query=qname, db=sname, outfmt=5, out=oname, word_size=9, evalue=10000, max_target_seqs=100000)()\n",
    "    f = open(oname, 'r')\n",
    "    blast_result_records = NCBIXML.parse(f)\n",
    "    record1 = next(blast_result_records)\n",
    "    record2 = next(blast_result_records)\n",
    "    \n",
    "    metrics = BlastMetrics(record2)\n",
    "    print(record2.query_length)\n",
    "\n",
    "    for m in [\n",
    "        'local_gap_compressed_percent_id',\n",
    "        'scaled_local_query_percent_id',\n",
    "        'scaled_local_symmetric_percent_id',\n",
    "        'local_E_value',\n",
    "        'query_align_start',\n",
    "        'query_align_end',\n",
    "        'subject_align_end',\n",
    "        'subject_align_start',\n",
    "        'query_align_len',\n",
    "        'query_align_cov',\n",
    "        'subject_align_len',\n",
    "        'subject_align_cov',\n",
    "        'bit_score'\n",
    "    ]: \n",
    "        print(metrics.compute_metric(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c65124",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
